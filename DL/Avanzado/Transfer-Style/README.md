<h2 align="center">
<p>Transferencia de estilo con VGG üñºÔ∏è</p>
</h2>

## ‚ÑπÔ∏è Introducci√≥n
En la transferencia de estilo hay dos im√°genes que se utilizan como entrada: la imagen de contenido y la imagen de estilo. A partir de estos, se crea una tercera imagen, llamada imagen generada. Esto es gracias a los kernels de las CNN's, que pueden aprender una representaci√≥n del mapa de caracter√≠sticas de la imagen; es decir, sus caracter√≠sticas y patrones m√°s relevantes. Al pasar de capas superficiales a capas profundas, la red neuronal convolucional puede detectar patrones complejos, lo que puede no tener mucho sentido para el ojo humano.

<p align="center">
  <img src="./src/kernels.png" />
</p>

Estas representaciones son la clave para la transferencia de estilos. Se utilizan para calcular la distancia de la imagen generada desde las im√°genes de estilo y contenido. Tenemos que asegurarnos de que la imagen generada conserva el contenido de la imagen de contenido y que el estilo es similar a la imagen de estilo. Es decir: la transferencia de estilo es un problema de optimizaci√≥n en el que tenemos que minimizar 3 funciones de p√©rdida: una para la p√©rdida de contenido, otra para la p√©rdida de estilo y otra llamada p√©rdida total.

En este repositorio se presenta una implementaci√≥n basada en VGG19, siguiendo los lineamientos del paper ["A Neural Algorithm of Artistic Style"](https://arxiv.org/abs/1508.06576) publicado en 2015.

## üß† Modelo base

El modelo base es VGG19, usaremos las siguientes capas (por √≠ndice): '0', '5', '10', '19' y '28'. Dichas capas seleccionadas son capas convolucionales, que ser√°n las √∫nicas piezas que extrearemos del modelo base (m√°s concretamente, las caracter√≠sticas que generan). Podemos usar una imagen clon inicial como entrada al modelo base, o tambi√©n podr√≠a ser un tensor aleatorio (hay mejores resultados como lo primero).

A continuaci√≥n se muestra la arquitectura VGG19:

<p align="center">
  <img src="./src/model.png" />
</p>

Si desea analizar la arquitectura m√°s a fondo, si√©ntase libre de editar el [modelo](model.py).

## ‚ñ∂ Demo
Instale las dependencias del archivo `requirements.txt` con el siguiente comando:
```bash
pip install -r requirements.txt --no-cache-dir
```

Para poder entrenar el modelo, ejecute el siguiente comando:

```bash
python train.py
```

Cada 200 iteraciones, la imagen resultado ser√° almacenada. A continuaci√≥n se muestra el resultado para 1000 iteraciones.
<p align="center">Imagen fuente</p>
<p align="center">
<img src="./src/wiki.jpg" />
</p>

<p align="center">Imagen estilo</p>
<p align="center">
<img src="./src/style.jpg" />
</p>

<p align="center">Imagen resultado</p>
<p align="center">
<img src="./src/wiki_style.png" />
</p>

Lo resultados podr√≠an mejorar si juegan con los hiperpar√°metros.