<h2 align="center">
<p>Segmentaci√≥n de im√°genes con UNET</p>
</h2>

## ‚ÑπÔ∏è Segmentaci√≥n
La segmentaci√≥n de im√°genes es un problema muy popular de visi√≥n por computadora que abarca desde campos de la medicina (localizaci√≥n de la zona afectada), hasta la conducci√≥n aut√≥noma. En la siguiente animaci√≥n se muestra la segmentaci√≥n *sem√°ntica* para diversos objetos (segmentaci√≥n no binaria).
<p align="center">
  <img src="./src/unet.gif" />
</p>

Para lograrlo se han inventado muchas arquitecturas, entre las que destacan Mask-RCNN o UNET. Trataremos m√°s a fondo la √∫ltima, que fue presentada en [este paper](https://arxiv.org/abs/1505.04597) con prop√≥sitos inicialmente m√©dicos, pero tambi√©n ha demostrado buen desempe√±o en una diversidad de otras tareas.

## üß† Modelo

La implementaci√≥n del modelo que presentamos en este repositorio ha sido levemente modificada para poder ser entrenada m√°s rapidamente (debido a que se requiere un hardware relativamente potente). Se sigui√≥ en la medida de lo posible los lineamientos del paper original. 

A continuaci√≥n se muestra la arquitectura de forma gr√°fica:

<p align="center">
  <img src="./src/unet.png" />
</p>

La arquitectura contiene dos piezas clave:
- **DoubleConv**: Clase que se encarga de hacer las dos convolucionales sucesivas (en un mismo nivel), como puede observar en la imagen (flechas azules). Usaremos esa clase para poder construir la parte *descendente* y *ascendente* de la UNET.
- **skip_connections**: Conexiones residuales que evitan la degradaci√≥n de la informaci√≥n que pasa por el cuello de botella (parte m√°s inferior). En c√≥digo, se representa mediante una concatenaci√≥n de tensores (aseg√∫rese que las dimensiones coincidan).

El modelo se ha modificado para poder hacer segmentaci√≥n binaria, pintando de blanco y negro la imagen resultante. Si desea hacer una segmentaci√≥n con m√°s categor√≠as, puede cambiar el n√∫mero de canales de salida y la funci√≥n de coste (inicialmente se usa una Binary Cross Entropy).

Si desea analizar la arquitectura m√°s a fondo, si√©ntase libre de editar el [modelo](model.py).

## üìÅ Dataset

Como los datos para entrenar esta arquitectura son dif√≠ciles de conseguir y/o de etiquetar manualmente, se ha recurrido a Kaggle. El [Dataset Kaggle "Carvana Image Masking"](https://www.kaggle.com/c/carvana-image-masking-challenge/data?select=train.zip) cuenta con im√°genes de coches con su correspondiente m√°scara de segmentaci√≥n. El dataset completo pesa 27GB pero solo se han descargado los archivos *train.zip* y *train_masks.zip*. Aseg√∫rese de colocar los datos en las siguientes carpetas:
- *train_masks* y *train_masks*, con un 95% de los datos datos totales.
- *val_masks* y *val_masks*, con un 5% de los datos datos totales.


## ‚ñ∂ Demo
Instale las dependencias del archivo `requirements.txt`.

Para poder entrenar el modelo, ejecute el siguiente comando:

```bash
python train.py
```

En el terminal, despu√©s de 1 √©poca se mostrar√° algo como:

<p align="center">
  <p align="center" >Accuracy despu√©s de 1 √©poca</p>
  <img src="./src/epoch_1.png" />
</p>

Se observa que los resultados son prometedores y con un accuracy muy aceptable.
En caso tenga un desbordamiento de memoria *cuda*, reduzca el tama√±o de lote (hiperpar√°metro *BATCH_SIZE*).

A continuaci√≥n se muestran dos predicciones hechas por el modelo:

<p align="center">
  <p align="center">Original 1</p>
  <img src="./saved_images/original_0.png" />
  <p align="center">Predicci√≥n 1</p>
  <img src="./saved_images/pred_0.png" />
</p>

<p align="center">
  <p align="center">Original 2</p>
  <img src="./saved_images/original_1.png" />
  <p align="center">Predicci√≥n 2</p>
  <img src="./saved_images/pred_1.png" />
</p>