<h2 align="center">
<p>Red Convolucional VGG</p>
</h2>

 TODO:
- ‚úÖ Implementaci√≥n en Pytorch
- ‚¨úÔ∏è Serializar el modelo entrenado

## ‚ÑπÔ∏è Introducci√≥n
El ImageNet Large Scale Visual Recognition Challenge (ILSVRC) es una competencia anual de visi√≥n por computadora. Cada a√±o, los equipos compiten en dos tareas. El primero es detectar objetos dentro de una imagen que provienen de 200 clases, lo que se denomina localizaci√≥n de objetos. El segundo es clasificar las im√°genes, cada una etiquetada con una de las 1000 categor√≠as, lo que se denomina clasificaci√≥n de im√°genes. VGG 16 fue propuesto por Karen Simonyan y Andrew Zisserman del Laboratorio del Grupo de Geometr√≠a Visual de la Universidad de Oxford en 2014 en el paper ["VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION"](https://arxiv.org/abs/1409.1556). Este modelo gan√≥ el 1er y 2do lugar en las categor√≠as anteriores en el desaf√≠o ILSVRC 2014.

Este modelo alcanza una precisi√≥n de prueba del 92,7% top-5 en el conjunto de datos ImageNet que contiene 14 millones de im√°genes que pertenecen a 1000 clases.

## üß† Modelo

VGG es una arquitectura de red neuronal convolucional cl√°sica. Se bas√≥ en un an√°lisis de c√≥mo aumentar la profundidad de dichas redes. La red utiliza peque√±os filtros de 3 x 3. La red se caracteriza por su simplicidad: los √∫nicos otros componentes son capas pooling y una capa completamente conectada.

A continuaci√≥n se muestran m√°s detalles de la arquitectura:

<p align="center">
  <img src="./src/model.png" />
</p>
<p align="center">
  <img src="./src/arq.png" />
</p>

Si desea analizar la arquitectura m√°s a fondo, si√©ntase libre de editar el [modelo](model.py).

## üìÅ Dataset

El dataset usado fue CIFAR10, consta de 60000 im√°genes en color, resoluci√≥n 32x32 y agrupada en 10 clases, con 6000 im√°genes por clase.

A continuaci√≥n se muestran las categor√≠as disponibles:

<p align="center">
  <img src="./src/cifar10.png" />
</p>

## ‚ö° Entrenamiento
<p align="center">
  <img src="./src/lightning.gif" />
</p>

Instale las dependencias del archivo `requirements.txt` con el siguiente comando:
```bash
pip install -r requirements.txt --no-cache-dir
```
Hay algunos detalles que usted debe conocer antes de entrenar:
- Para entrenar sin dificultades necesita un GPU Nvidia con 8GB-16GB de memoria. Yo lo entrene en una 1050Ti y tuve constantes desbordamiento de memoria CUDA (La resoluci√≥n 224x224 de la im√°genes suele ser el problema). Para solucionar dicho problema, tuve que disminuir el n√∫mero de neuronas en las capas densas, disminuir el tama√±o de lote y disminuir tama√±o de las im√°genes de entrada. 
- Hay un sesgo introducido en el dataset CIFAR10 que pude observar, y es que al momento de hacer un resize de 32x32 a 224x224, la imagen es muy pobre visualmente. Una soluci√≥n podr√≠a ser usar un dataset con resoluciones cercanas a 224x224. Una soluci√≥n temporal ser√≠a disminuir tama√±o de las im√°genes de entrada, como mencion√© en el punto anterior. 
-La selecci√≥n de la tasa de aprendizaje afectar√° bastante a la convergencia del modelo. El *lr* que eleg√≠ da se√±ales de convergencia (tasas m√°s grandes llevan a un *loss* que no baja del 2.3).

Para poder entrenar el modelo, ejecute el siguiente comando:

```bash
python train.py
```

Para visualizar c√≥mo disminuye la p√©rdida, ejecute **Tensorboard**:
```bash
tensorboard --logdir "./"
```

Tambi√©n he a√±adido una [variante](train_lightning.py) de [*train.py*](train.py), usando Pytorch Lightning, para poder entrenar el modelo de forma m√°s eficiente. Ejecute el siguiente comando:
```bash
python train_lightning.py
```
